---
title: "Code for MTHM601 report"
output:
  pdf_document: default
  html_document: default
date: "2025-01-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(tidyverse)
library(patchwork)
library(dplyr)
library(lubridate)
library(ggpubr)
library(mgcv)
library(sf)
library(tmap)
library(leaflet)
library(spatstat)
library(flextable)
library(MASS)
library(lme4)
library(emmeans)

```

## Load Roadkill dataset

```{r}
roadkill_full <- read.csv("records-2024-12-03.csv")
```

## Data Wrangling

### Rename columns

Using the dplyr package, rename columns so they are more manageable.

```{r}
head(roadkill_full)

rk <- roadkill_full %>% 
  rename(
    species = Common.name,
    date = Start.date,
    day = Start.date.day,
    month = Start.date.month,
    year = Start.date.year,
    lat = Latitude..WGS84.,
    long = Longitude..WGS84.,
    country = State.Province
  )

head(rk)
```

Create dataset with only necessary columns. Using the dplyr package.

```{r}
roadkill <- rk %>% dplyr::select(species, Taxon.Rank, date, day, month, year, lat, long, country, Kingdom, Phylum, Class, Order, Family, Genus)


```

### Add a season column

I am interested in seasonal variation, not just the exact date so I am going to use an if-else function to create a season column.

```{r}
get_season <- function(month) {
  if (month %in% c(12, 1, 2)) {
    return("Winter")
  } else if (month %in% c(3, 4, 5)) {
    return("Spring")
  } else if (month %in% c(6, 7, 8)) {
    return("Summer")
  } else if (month %in% c(9, 10, 11)) {
    return("Autumn")
  } else {
    return(NA)
  }
}


roadkill <- roadkill %>%
  mutate(season = sapply(month, get_season))


head(roadkill)


```

Noticed that date is coming up as NA - so I will combine the day, month and year columns to create a new date column

```{r}
roadkill <- roadkill %>%
  mutate(date = as.Date(paste(year, month, day, sep = "-"), format = "%Y-%m-%d"))

head(roadkill)


```

### Format data types

```{r}
roadkill$day <- as.integer(roadkill$day)
roadkill$month <- as.integer(roadkill$month)
roadkill$year <- as.integer(roadkill$year)
roadkill$species <- as.factor(roadkill$species)
roadkill$Taxon.Rank <-as.factor(roadkill$Taxon.Rank)
roadkill$lat <- as.numeric(roadkill$lat)
roadkill$long <- as.numeric(roadkill$long)
roadkill$country <-as.factor(roadkill$country)
roadkill$Kingdom <-as.factor(roadkill$Kingdom)
roadkill$Phylum <-as.factor(roadkill$Phylum)
roadkill$Class <-as.factor(roadkill$Class)
roadkill$Order <-as.factor(roadkill$Order)
roadkill$Family <-as.factor(roadkill$Family)
roadkill$Genus <-as.factor(roadkill$Genus)
roadkill$season <-as.factor(roadkill$season)

str(roadkill)
```

### Remove all birds and reptiles - only keep mammals

```{r}

mammal_roadkill <- roadkill %>%
  filter(grepl("mammalia", Class, ignore.case = TRUE))

head(mammal_roadkill)
str(mammal_roadkill)


```

### Remove any NAs or blanks

```{r}

mammal_roadkill <- mammal_roadkill %>%
  mutate(species = trimws(species)) %>% 
  filter(species != "", !is.na(species)) 

head(mammal_roadkill)
str(mammal_roadkill)

```

### Unique species

```{r}
unique(mammal_roadkill$species)
```

### Remove "indet.deer" and "polecat-ferret hybrid" and "rabbit and hares"

Because they are not to a species level, I opted to remove any rows that were called these things.

```{r}
mammal_roadkill <- mammal_roadkill %>%
  filter(!species %in% c("Indet. Deer", "Polecat-Ferret", "rabbits and hares"))
```

### Standardise species names

Some species were hard to identify to species level, so I decided to group them. Also grey squirrel and squirrel, I grouped as Red Squirrels are rare in most parts of the country.

```{r}

mammal_roadkill <- mammal_roadkill %>%
  mutate(species = case_when(
    species %in% c("Eastern Grey Squirrel", "Squirrel") ~ "Grey Squirrel",
    species %in% c("Brown Rat", "Rat spp.") ~ "Rats",
    species %in% c("Wood Mouse", "House Mouse", "Small Mouse", "Yellow-necked Mouse") ~ "Mice",
    species %in% c("Bat", "Pipistrelle Bat species", "Soprano Pipistrelle", "Brown Long-eared Bat", "Pipistrelle") ~ "Bats",
    species %in% c("Field Vole", "Bank Vole", "Vole") ~ "Voles",
    species %in% c("Brown Hare", "Mountain Hare", "Irish Hare") ~ "Hares",
    TRUE ~ species 
  ))


# View the updated dataset
head(mammal_roadkill)
unique(mammal_roadkill$species)

```

### Create new CSV file

Now that I have finished with the data wrangling, I will create a new CSV file.

```{r}
write.csv(mammal_roadkill, "updated_roadkill.csv", row.names = FALSE)
```

### Exploratory Data Visualisation

#### Monthly reports

```{r}
monthly_yearly_data <- mammal_roadkill %>%
  group_by(year, month) %>%
  summarise(total_roadkill = n())

monthly_yearly_data <- monthly_yearly_data %>%
  mutate(month = factor(month, levels = 1:12, labels = month.name))

print(monthly_yearly_data)


```

```{r}
p1 <- ggplot(monthly_yearly_data, aes(x = month, y = total_roadkill, group = year, color = factor(year))) +
  geom_line() +
  theme_minimal() +
  labs(
    title = "Monthly Roadkill Trends by Year",
    x = "Month",
    y = "Total Roadkill",
    color = "Year"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p1
```

```{r}
monthly_roadkill <- mammal_roadkill %>%
  group_by(year, month) %>%
  summarise(reports = n(), .groups = "drop")

monthly_roadkill <- monthly_roadkill %>%
  mutate(date = as.Date(paste(year, month, 1, sep = "-")))


p2 <- ggplot(monthly_roadkill, aes(x = date, y = reports)) +
  geom_line(color = "black", linewidth = 0.5) +
  theme_minimal() +
  labs(
    title = "(a)",
    x= NULL,
    y = NULL  ) +
  ylim(0,2500)+
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p2
```

## Scale spike in 2019

Following the methods from Raymond et al. 2021, I scaled the data based on monthly proportions and then I subsampled it 10,000 times and took the mean.

```{r}
library(dplyr)

scaled_data <- mammal_roadkill %>%
  group_by(species, year, month) %>%
  summarise(monthly_total = n(), .groups = "drop") %>%  
  group_by(species, year) %>%
  mutate(
    annual_total = sum(monthly_total), 
    monthly_percentage = round((monthly_total / annual_total) * 100, 1) 
  ) %>%
  ungroup()

head(scaled_data)


```

```{r}

set.seed(222) 

adjusted_data <- scaled_data %>%
  group_by(species) %>%
  mutate(adjusted_count = case_when(
    year == 2019 & month == 7 & monthly_total > 1 ~ round(monthly_total * 2 / 3), 
    year == 2019 & month == 8 & monthly_total > 1 ~ round(monthly_total / 2),    
    TRUE ~ monthly_total 
  )) %>%
  ungroup()

#Subsampling repeated 10,000 times and taking the mean count
adjusted_data <- adjusted_data %>%
  group_by(species, year, month) %>%
  summarise(
    mean_adjusted_count = mean(replicate(10000, {
      if (year == 2019 & month == 7 && monthly_total > 1) {
        round(monthly_total * 2 / 3)
      } else if (year == 2019 & month == 8 && monthly_total > 1) {
        round(monthly_total / 2)
      } else {
        monthly_total
      }
    })),
    .groups = "drop"
  )

head(adjusted_data)


```

Plot this adjusted data

```{r}
total_adjusted_data <- adjusted_data %>%
  group_by(year, month) %>%
  summarise(total_reports = sum(mean_adjusted_count, na.rm = TRUE), .groups = "drop") %>%
  mutate(date = ymd(paste(year, month, "01", sep = "-")))


p3 <- ggplot(total_adjusted_data, aes(x = date, y = total_reports)) +
  geom_line(color = "black", linewidth = 0.5) +
  theme_minimal() +
  labs(
    title = "(b)",
    x = NULL,
    y = "Reports"
  ) +
  ylim(0,2500)+
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
p3
```

I decided this still resulted in too big of a spike so I will remove July - September 2019 and then ttry imputing values.

### Remove July - September 2019

```{r}

mammal_roadkill_no_spike <- mammal_roadkill %>%
  filter(!(format(date, "%Y-%m") %in% c("2019-07", "2019-08", "2019-09")))

```

### Impute values for July - September 2019

I will turn it into monthly values and then add blank rows for July - September 2019 and then impute values.

```{r}

monthly_no_spike <- mammal_roadkill_no_spike %>%
  group_by(year, month) %>%
  summarise(total_roadkill = n())

monthly_no_spike <- monthly_no_spike %>%
  mutate(month = factor(month, levels = 1:12, labels = month.name))

print(monthly_no_spike)

imputed_rk <- monthly_no_spike %>%
  mutate(month = factor(month, levels = month.name)) %>%
  group_by(month) %>%  
  mutate(monthly_mean = mean(total_roadkill, na.rm = TRUE),  
         value = ifelse(is.na(total_roadkill) & year == 2019, monthly_mean, total_roadkill)) %>%  
  dplyr::select(-monthly_mean)  

print(imputed_rk)
```

Change of plan, I realised this won't work for what I need as I don't just want monthly values. I am going to calculate the mean for all July's and August's and September's (excluding 2019) and from that mean, I will randomly select that amount of reports from July and August and September in 2019 and keep those, discarding the others. Because I'm not assessing anything at a species level, it doesn't matter if I lose individual species.

```{r}
july_mean <- mammal_roadkill_no_spike %>%
  filter(format(date, "%m") == "07") %>%  
  group_by(year = format(date, "%Y")) %>%  
  summarise(july_count = n()) %>%  
  summarise(mean_july_reports = mean(july_count, na.rm = TRUE)) 

print(round(july_mean))

aug_mean <- mammal_roadkill_no_spike %>%
  filter(format(date, "%m") == "08") %>%  
  group_by(year = format(date, "%Y")) %>%  
  summarise(aug_count = n()) %>%  
  summarise(mean_aug_reports = mean(aug_count, na.rm = TRUE))  

print(round(aug_mean))

sept_mean <- mammal_roadkill_no_spike %>%
  filter(format(date, "%m") == "09") %>%  
  group_by(year = format(date, "%Y")) %>%  
  summarise(sept_count = n()) %>%  
  summarise(mean_sept_reports = mean(sept_count, na.rm = TRUE))  

print(round(sept_mean))
```

### Choose rows from 2019

```{r}
set.seed(2108)
random_sample_july_2019 <- mammal_roadkill %>%
  filter(format(date, "%Y-%m") == "2019-07") %>%
  sample_n(363)

print(random_sample_july_2019)

set.seed(2108)
random_sample_aug_2019 <- mammal_roadkill %>%
  filter(format(date, "%Y-%m") == "2019-08") %>%
  sample_n(383)

print(random_sample_aug_2019)

set.seed(2108)
random_sample_sept_2019 <- mammal_roadkill %>%
  filter(format(date, "%Y-%m") == "2019-09") %>%
  sample_n(420)

print(random_sample_sept_2019)
```

### Add these into the dataset

```{r}
mammal_no_spike <- mammal_roadkill_no_spike %>%
  bind_rows(random_sample_july_2019, random_sample_aug_2019, random_sample_sept_2019) %>%
  arrange(date)


```

### Plot

```{r}
monthly <- mammal_no_spike %>%
  group_by(year, month) %>%
  summarise(reports = n(), .groups = "drop")

monthly <- monthly %>%
  mutate(date = as.Date(paste(year, month, 1, sep = "-")))


p4 <- ggplot(monthly, aes(x = date, y = reports)) +
  geom_line(color = "black", linewidth = 0.5) +
  theme_minimal() +
  labs(
    title = "(c)",
    x= NULL,
    y = NULL  ) +
  ylim(0, 2500) +
  scale_x_date(date_labels = "%Y", date_breaks = "1 year") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p4
```

Plot all 3 options together without their x labels.

```{r}
(p2 + theme(axis.title.x = element_blank(), axis.text.x = element_blank())) /
(p3 + theme(axis.title.x = element_blank(), axis.text.x = element_blank())) /
p4
```

## Met-Office data

Rainfall and temperature data from the met office don't download to excel files, just txt URLs so I have to load these datasets in a different way.

### Load dataset - temperature

Load dataset, turn it into a table, filter to the years I am interested in and then rearrange the table so that it is 'tidy' and each row reflects one month.

```{r}
tempURL <- "https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/Tmean/date/UK.txt"

temp <- read.table(tempURL, header = TRUE, skip = 5, stringsAsFactors = FALSE)

filtered_temp <- temp %>%
  filter(year >= 2014 & year <= 2024)

data_long <- filtered_temp %>%
  pivot_longer(
    cols = jan:dec,  # Month columns
    names_to = "month",
    values_to = "mean_temperature"
  ) %>%
  mutate(
    month = match(month, c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")),  # Convert month to integer
    year = as.numeric(year)  # Ensure year is numeric
  )

```

### Load dataset - rain

And now the same for the rain dataset.

```{r}
rainURL <- "https://www.metoffice.gov.uk/pub/data/weather/uk/climate/datasets/Rainfall/date/UK.txt" 

rain <- read.table(rainURL, header = TRUE, skip = 5, stringsAsFactors = FALSE)

filtered_rain <- rain %>%
  filter(year >= 2014 & year <= 2024)

# Step 5: Reshape the data from wide to long format
long_rain <- filtered_rain %>%
  pivot_longer(
    cols = jan:dec,  # Month columns
    names_to = "month",
    values_to = "rainfall"
  ) %>%
  mutate(
    month = match(month, c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec")),
    year = as.numeric(year)
  )
```

### Plot temperature

```{r}
t1 <- ggplot(data_long, aes(x = month, y = mean_temperature, group = year, color = factor(year))) +
  geom_smooth(se = FALSE, method = "loess", linewidth = 1) +
  geom_vline(xintercept = c(2.5, 5.5, 8.5, 11.5), linetype = "dashed", color = "black", linewidth = 0.8) +
  scale_x_continuous(
    breaks = 1:12,  # Numeric positions (1 to 12 for months)
    labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")  # Month names
  ) +
  labs(
    title = "Mean Temperature Over Months (2014-2024, UK)",
    x = "Month",
    y = "Mean Temperature (°C)",
    color = "Year"
  ) +
  theme_minimal()

t1

```

#### Plot rain

```{r}
t2 <- ggplot(long_rain, aes(x = month, y = rainfall, group = year, color = factor(year))) +
  geom_smooth(se = FALSE, method = "loess", linewidth = 1) +
  geom_vline(xintercept = c(2.5, 5.5, 8.5, 11.5), linetype = "dashed", color = "black", linewidth = 0.8) +
  scale_x_continuous(
    breaks = 1:12,  # Numeric positions (1 to 12 for months)
    labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")  # Month names
  ) +
  labs(
    title = "Rainfall Over Months (2014-2024, UK)",
    x = "Month",
    y = "Rainfall (mm)",
    color = "Year"
  ) +
  theme_minimal()

t2
```

```{r}
t1/t2 + plot_layout(guides = "collect")
```

## Combine roadkill and climate data

```{r}
climate_data <- long_rain %>%
  full_join(data_long, by = c("year", "month"))


roadkill_climate <- mammal_no_spike %>%
  left_join(climate_data, by = c("year", "month"))

roadkill_climate <- roadkill_climate %>%
  mutate(across(ends_with(".x"), as.numeric)) %>%   
  mutate(across(ends_with(".y"), as.numeric)) 


roadkill_with_climate <- roadkill_climate %>%
  mutate(
    seasonal_rainfall = case_when(
      season == "Winter" ~ win.x + win.y,
      season == "Spring" ~ spr.x + spr.y,
      season == "Summer" ~ sum.x + sum.y,
      season == "Autumn" ~ aut.x + aut.y,
      TRUE ~ NA_real_  # Default for unexpected cases
    )
  ) %>%
  dplyr::select(-win.x, -win.y, -spr.x, -spr.y, -sum.x, -sum.y, -aut.x, -aut.y)


roadkill_counts <- roadkill_with_climate %>%
  group_by(year, month) %>%
  summarise(roadkill_count = n(), .groups = "drop")

roadkill_with_climate <- roadkill_counts %>%
  left_join(climate_data, by = c("year", "month"))


get_season <- function(month) {
  if (month %in% c(12, 1, 2)) {
    return("Winter")
  } else if (month %in% c(3, 4, 5)) {
    return("Spring")
  } else if (month %in% c(6, 7, 8)) {
    return("Summer")
  } else if (month %in% c(9, 10, 11)) {
    return("Autumn")
  } else {
    return(NA)
  }
}


roadkill_with_climate <- roadkill_with_climate %>%
  mutate(season = sapply(month, get_season))

roadkill_with_climate$season <- factor(roadkill_with_climate$season, 
                                       levels = c("Winter", "Spring", "Summer", "Autumn"))
```

## Seasonal Trends

Graph of seasonal trends

```{r}
seasonal_trends <- mammal_no_spike %>%
  group_by(season, year) %>%
  summarise(roadkill_count = n(), .groups = "drop")

ggplot(seasonal_trends, aes(x = year, y = roadkill_count, color = season)) +
  geom_line(linewidth = 1) +
  labs(
    title = "Seasonal Trends in Mammalian Roadkill",
    x = "Year",
    y = "Number of Roadkill Reports",
    color = "Season"
  ) +
  theme_minimal()

```

```{r}
seasonal_data <- mammal_no_spike %>%
  group_by(year, season) %>%
  summarise(Count = n(), .groups = 'drop')

ggplot(seasonal_data, aes(x = season, y = Count)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Seasonal Variation in Roadkill Counts",
       x = "Season",
       y = "Roadkill Counts") +
  theme_minimal()
```

Determine which model to use

```{r}
# Model 1: Year only
model_year <- glm.nb(Count ~ year, data = seasonal_data)

# Model 2: Season only
model_season <- glm.nb(Count ~ season, data = seasonal_data)

# Model 3: Both Year and Season
model_both <- glm.nb(Count ~ year + season, data = seasonal_data)

# Model 4: Year and Season with Interaction
model_interaction <- glm.nb(Count ~ year * season, data = seasonal_data)

# Compare models using AIC
AIC(model_year, model_season, model_both, model_interaction)

lrt_year_vs_season <- anova(model_year, model_season, test = "Chisq")
lrt_season_vs_both <- anova(model_season, model_both, test = "Chisq")
lrt_both_vs_interaction <- anova(model_both, model_interaction, test = "Chisq")


```

### Creating a table for report

```{r}



model_comparison <- data.frame(
  Model = c("Year", "Season", "Year + Season", "Year * Season"),
  AIC = c(AIC(model_year),
          AIC(model_season),
          AIC(model_both),
          AIC(model_interaction)),
  LogLik = c(logLik(model_year),
             logLik(model_season),
             logLik(model_both),
             logLik(model_interaction)),
  DF = c(attr(logLik(model_year), "df"),
         attr(logLik(model_season), "df"),
         attr(logLik(model_both), "df"),
         attr(logLik(model_interaction), "df")),
  LR_Stat = c(NA, 
              lrt_year_vs_season$`LR stat.`[2],
              lrt_season_vs_both$`LR stat.`[2],
              lrt_both_vs_interaction$`LR stat.`[2]),
  P_Value = c(NA, 
              lrt_year_vs_season$`Pr(Chi)`[2],
              lrt_season_vs_both$`Pr(Chi)`[2],
              lrt_both_vs_interaction$`Pr(Chi)`[2])
)




ft <- model_comparison %>%
  mutate(P_Value = ifelse(P_Value < 0.01, "<0.01", as.character(round(P_Value, 2)))) %>%
  flextable() %>%
  colformat_double(j = c(2:6), digits = 2) %>% 
  align(align = 'center', part = 'header') %>% 
  align(align = 'center', part = 'body') %>%
  bold(~P_Value == "<0.01", j = "P_Value")


ft

```

Now I've picked the best model, i get a summary of it which tells me which seasons are significant

```{r}
summary(model_season)
```

## Spatial Trend

I decided to make an interactive map of the roadkill reports per region in the uk.

```{r}
uk_regions <- st_read("ITL2_JAN_2025_UK_BFE.shp")


roadkill_sf <- mammal_no_spike %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326)  


uk_regions <- st_transform(uk_regions, crs = 4326)


roadkill_with_regions <- st_join(roadkill_sf, uk_regions, join = st_intersects)

print(names(uk_regions))

spatial_trends <- roadkill_with_regions %>%
  group_by(ITL225NM) %>%  
  summarise(roadkill_count = n(), .groups = "drop")

spatial_trends_map <- uk_regions %>%
  mutate(NAME = as.character(ITL225NM)) %>% 
  left_join(as.data.frame(spatial_trends), by = "ITL225NM")

tmap_mode("view")
m1 <- tm_shape(spatial_trends_map) +
  tm_polygons("roadkill_count", 
              title = "Roadkill Reports", 
              palette = "YlOrRd", 
              border.alpha = 0.5,
              id = "ITL225NM")

m1
```

Static map to include in report

```{r}
tmap_mode("plot")

m2 <- tm_shape(spatial_trends_map) +
  tm_polygons("roadkill_count", 
              title = "Roadkill Reports", 
              palette = "YlOrRd", 
              border.alpha = 0.5,
              id = "ITL225NM") +
  tm_layout(
    legend.position = c("left", "top"),  
    legend.text.size = 0.5,                 
    legend.title.size = 0.8                 
  )

m2
```

I wanted to look at seasonal trends but there were too many reports for the maps to show anything

```{r}

ggplot(roadkill_sf) +
  geom_sf(aes(colour = season), size = 1) +
  facet_wrap(~season) +
  labs(title = "Distribution of Reports by Season",
       x = "Longitude", y = "Latitude") +
  theme_minimal()
```

Again, even split into month there is not visually much difference

```{r}
ggplot(roadkill_sf) +
  geom_sf(aes(colour = month), size = 1) +
  facet_wrap(~month) +
  labs(title = "Distribution of Reports by Season",
       x = "Longitude", y = "Latitude") +
  theme_minimal()
```

Test normality

```{r}
hist(spatial_trends_map$roadkill_count, xlab = "Counts", breaks = 10)

qqnorm(spatial_trends_map$roadkill_count) 
qqline(spatial_trends_map$roadkill_count, col = "red")
```

Check for overdispersion

```{r}
# Check mean and variance
mean_count <- mean(spatial_trends_map$roadkill_count)
var_count <- var(spatial_trends_map$roadkill_count)
print(mean_count)
print(var_count)
#mean is a lot smaller than variance so negative binomial distribvution is likely better but i will calculate the dispersion statistic for the poisson model
```

```{r}
poisson_model <- glm(roadkill_count ~ NAME, family = poisson(link = "log"), data = spatial_trends_map)

dispersion <- sum(residuals(poisson_model, type = "pearson")^2) / df.residual(poisson_model)
print(dispersion)

plot(poisson_model)
```

```{r}
str(spatial_trends_map)

# Remove geometry columns for modeling
region_data <- st_drop_geometry(spatial_trends_map)
region_data$NAME <- as.factor(region_data$NAME)
region_data$roadkill_count <- as.numeric(region_data$roadkill_count)

# Check for missing values
colSums(is.na(region_data))

# Remove rows with missing values
region_data <- na.omit(region_data)

# Check for infinite values
sum(is.infinite(region_data$roadkill_count))  # Should be 0

# Check for NaN values
sum(is.nan(region_data$roadkill_count))  # Should be 0

region_data <- region_data %>% dplyr::select (NAME, roadkill_count)

str(region_data)


library(forcats)
region_data$NAME <- fct_lump(region_data$NAME, n = 10)  # Keep top 20 levels, lump others into "Other"
table(region_data$NAME)


# Check levels of NAME
levels(region_data$NAME)

library(MASS)
simple_nb <- glm.nb(roadkill_count ~ 1, data = region_data)
summary(simple_nb)


region_nb <- glm.nb(roadkill_count ~ NAME, data = region_data)

plot(region_nb)
```

```{r}
region_data$region_group <- ifelse(region_data$NAME %in% c(
  "Tees Valley", 
  "Northumberland, Durham and Tyne & Wear", 
  "Cumbria", 
  "Greater Manchester", 
  "Lancashire", 
  "Cheshire", 
  "Merseyside", 
  "North Yorkshire", 
  "South Yorkshire", 
  "West Yorkshire", 
  "East Yorkshire and Northern Lincolnshire"
), "North",
ifelse(region_data$NAME %in% c(
  "Derbyshire and Nottinghamshire", 
  "Leicestershire, Rutland and Northamptonshire", 
  "Lincolnshire", 
  "Herefordshire, Worcestershire and Warwickshire", 
  "Shropshire and Staffordshire", 
  "West Midlands", 
  "Gloucestershire and Wiltshire"
), "Midlands",
ifelse(region_data$NAME %in% c(
  "Bedfordshire and Hertfordshire", 
  "Essex", 
  "Cambridgeshire and Peterborough", 
  "Norfolk", 
  "Suffolk", 
  "Berkshire, Buckinghamshire and Oxfordshire", 
  "Surrey, East and West Sussex", 
  "Hampshire and Isle of Wight", 
  "Kent", 
  "Cornwall and Isles of Scilly", 
  "Devon", 
  "West of England", 
  "North Somerset, Somerset and Dorset", 
  "Outer London - East and North East", 
  "Outer London - South", 
  "Outer London - West and North West", 
  "Inner London - East", 
  "Inner London - West"
), "South",
ifelse(region_data$NAME %in% c(
  "North Wales", 
  "Mid and South West Wales", 
  "South East Wales"
), "Wales",
ifelse(region_data$NAME %in% c(
  "Eastern Scotland", 
  "East Central Scotland", 
  "Highlands and Islands", 
  "West Central Scotland", 
  "North Eastern Scotland", 
  "Southern Scotland"
), "Scotland",
 ifelse(region_data$NAME %in% c("Northern Ireland"), "Northern Ireland", NA))))))

# Convert to factor for modeling
region_data$region_group <- as.factor(region_data$region_group)

# Check group sizes
table(region_data$region_group)

```

```{r}
nb_model <- glm.nb(roadkill_count ~ region_group, data = region_data)

summary(nb_model)

par(mfrow = c(2,2))
plot(nb_model)
```

```{r}
# Predicted mean counts
region_data$predicted <- predict(nb_model, type = "response")

# Bar plot of predicted counts
ggplot(region_data, aes(x = region_group, y = predicted)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Predicted Roadkill Counts by Region Group",
       x = "Region Group", y = "Predicted Roadkill Count") +
  theme_minimal()

```

```{r}
# Pairwise comparisons between region groups
pairwise_results <- emmeans(nb_model, pairwise ~ region_group, type = "response")

# View results
summary(pairwise_results)

```

```{r}
emmeans_table <- as.data.frame(pairwise_results$emmeans) %>%
  mutate(
    response = round(response, 2),          # Round Predicted Count
    SE = round(SE, 2),                     # Round Standard Error
    asymp.LCL = round(asymp.LCL, 2),       # Round CI Lower
    asymp.UCL = round(asymp.UCL, 2)        # Round CI Upper
  ) %>%
  rename(
    `Region Group` = region_group,
    `Predicted Count` = response,
    `Standard Error` = SE,
    `95% CI (Lower)` = asymp.LCL,
    `95% CI (Upper)` = asymp.UCL
  )


et <- emmeans_table %>%
  flextable() %>%
  colformat_double(j = c("Predicted Count", "Standard Error", "95% CI (Lower)", "95% CI (Upper)"), digits = 2) %>% 
  align(align = 'center', part = 'header') %>% 
  align(align = 'center', part = 'body') %>%
  autofit()

et
```

## Role of temp and rainfall

```{r}


# Scatter plot with regression line
ggscatter(roadkill_with_climate, x = "mean_temperature", y = "roadkill_count",
          add = "reg.line", conf.int = TRUE,
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Temperature (°C)", ylab = "Roadkill Count")


ggscatter(roadkill_with_climate, x = "rainfall", y = "roadkill_count",
          add = "reg.line", conf.int = TRUE,
          cor.coef = TRUE, cor.method = "pearson",
          xlab = "Rainfall (cm)", ylab = "Roadkill Count")

# Linear regression model
model <- lm(roadkill_count ~ mean_temperature + rainfall, data = roadkill_with_climate)

# Summary of the model
summary(model)

par(mfrow = c(2, 2))
plot(model)
```

```{r}
glm_poisson_climate <- glm(roadkill_count ~ mean_temperature + rainfall, family = poisson, data = roadkill_with_climate)

summary(glm_poisson_climate)

climate_dispersion <- sum(residuals(glm_poisson_climate, type = "pearson")^2) / df.residual(glm_poisson_climate)

climate_dispersion
```

Because it is over-dispersed, I will use a negative binomial family instead

```{r}
glm_nb_climate <- glm.nb(roadkill_count ~ mean_temperature + rainfall, data = roadkill_with_climate)

summary(glm_nb_climate)

par(mfrow = c(2, 2))
plot(glm_nb_climate)
```

```{r}
#Temperature
ggplot(roadkill_with_climate, aes(x = mean_temperature, y = roadkill_count)) +
  geom_point(alpha = 0.5) +
  stat_smooth(method = "glm.nb", se = TRUE) +  
  labs(title = "Effect of Temperature on Roadkill Counts",
       x = "Temperature (°C)",
       y = "Roadkill Count")

#Rain
ggplot(roadkill_with_climate, aes(x = rainfall, y = roadkill_count)) +
  geom_point(alpha = 0.5) +
  stat_smooth(method = "glm.nb", se = TRUE) +  
  labs(title = "Effect of Rainfall on Roadkill Counts",
       x = "Rainfall (mm)",
       y = "Roadkill Count")

```
